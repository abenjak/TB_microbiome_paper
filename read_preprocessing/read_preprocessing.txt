# Raw reads were processed in the following way. For every R1 and R2 fastq file:

# Trim bad quality 3' of the reads using FASTX-toolkit. Example:
zcat <sample_id>_S*_L001_R1_001.fastq.gz | fastx_trimmer -Q 33 -t 10 -z -o <sample_id>_L001_R1_001_trimmed-last-10.fastq.gz
zcat <sample_id>_S*_L001_R2_001.fastq.gz | fastx_trimmer -Q 33 -t 50 -z -o <sample_id>_L001_R2_001_trimmed-last-50.fastq.gz

# In theory, SeqPrep should handle inconsistencies between R1 and R2 during merging by choosing the higher-quality base for consensus calling of the merged region.
# Nevertheless, many samples had a drastic quality drop at specific length points, so we decided to remove such regions as precaution.
# The -t parameter was chosen after investigating the quality plots of the raw reads (generated by fastqc).
# The goal was to remove regions where the qualities suddenly dropped for most reads, but keeping enough sequence for pair overlap. Usually -t was 10-30 for R1 and 30-60 for R2.
# We opted to not use a per-read quality filtering strategy because we were concerned by the possibility that some species-related sequence patterns could result in a biased quality profile. However, the impact of different filtering/trimming strategies on final results was not tested. Nevertheless, such an effect is not expected to be very large in a reference-based OTU picking.


# Merge R1 and R2 using SeqPrep:
runSeqPrep.sh <sample_id>_L001_R1_001_trimmed-last-10.fastq.gz <sample_id>_L001_R2_001_trimmed-last-50.fastq.gz 30 <sample_id>
